{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyM0MA9kSr1M3AiygrKsj5Eq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGKobelev/Home/blob/main/intern_3/unilit_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxoHqaytSMJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a492493-1fa0-487c-fb3c-3d08197a2cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование в формат csv"
      ],
      "metadata": {
        "id": "Q5FA6TlXLg4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка файла Excel\n",
        "combined_df = pd.read_excel('/content/drive/MyDrive/Unilit/Копия Обращения.xlsx', engine='openpyxl')\n",
        "\n",
        "# Сохранение в формат CSV\n",
        "csv_file_path = '/content/drive/MyDrive/Unilit/appeals_file.csv'\n",
        "combined_df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"Файл успешно сохранен в формате CSV: {csv_file_path}\")\n"
      ],
      "metadata": {
        "id": "imJrtFhrLhyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a38f6f-b982-4d62-8a59-135932004890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно сохранен в формате CSV: /content/drive/MyDrive/Unilit/appeals_file.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перевод текстов к нижнему регистру и удаление лишних пробелов и символов."
      ],
      "metadata": {
        "id": "PS5Px9X5N1m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "CWoXZUN9WT7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64d29df-1744-46ee-869d-473e8f2a37c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=aee9e461db7001d24640edc0128a01168e9be49bcf5c9b8aaa525a96cff55b53\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pymorphy2\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Загрузка стоп-слов (требуется одноразовая загрузка)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Инициализация анализатора pymorphy2\n",
        "ma = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "# Определение стоп-слов для русского языка\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "\n",
        "# Загрузка данных, игнорируя первый ряд как заголовок\n",
        "file_path = '/content/drive/MyDrive/Unilit/appeals_file.csv'\n",
        "combined_df = pd.read_csv(file_path, header=1)  # Загружаем, начиная со второго ряда\n",
        "\n",
        "# Переименование столбцов\n",
        "combined_df.columns = ['№', 'Дата обращения', 'Суть обращения', 'Характер обращ', 'Комментарии инженера']\n",
        "\n",
        "# Функция для очистки и нормализации текста\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):  # Проверка, что text является строкой\n",
        "        return \"\"\n",
        "    # Удаление ненужных символов\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.replace(\"\\\\\", \" \").replace(u\"╚\", \" \").replace(u\"╩\", \" \")\n",
        "    text = text.lower()\n",
        "    text = re.sub('-\\s*\\r\\n|\\r\\n', '', text)  # удаление переносов строк\n",
        "    text = \" \".join(ma.parse(word)[0].normal_form for word in text.split())\n",
        "    text = re.sub('\\s+', ' ', text)  # замена нескольких пробелов одним\n",
        "    # Удаление стоп-слов\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n",
        "\n",
        "# Применение функции очистки и нормализации к столбцам 'Суть обращения' и 'Комментарии инженера'\n",
        "combined_df['appeals_reduct'] = combined_df['Суть обращения'].apply(clean_text)\n",
        "combined_df['engineer_comments_reduct'] = combined_df['Комментарии инженера'].apply(clean_text)\n",
        "\n",
        "# Сохранение очищенного DataFrame в формате CSV\n",
        "output_csv_path = '/content/drive/MyDrive/Unilit/clean_appeals_file.csv'\n",
        "combined_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(\"Данные успешно очищены и сохранены.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q9Yv9A3hUv9",
        "outputId": "557c42d1-b506-4ebf-bb33-536ba57847b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Данные успешно очищены и сохранены.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pymorphy2\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Инициализация анализатора pymorphy2\n",
        "ma = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "# Загрузка данных\n",
        "file_path = '/content/drive/MyDrive/Unilit/clean_appeals_file.csv'\n",
        "combined_df = pd.read_csv(file_path)\n",
        "\n",
        "# Замена NaN на пустые строки в столбцах 'appeals_reduct' и 'engineer_comments_reduct'\n",
        "combined_df['appeals_reduct'] = combined_df['appeals_reduct'].fillna('')\n",
        "combined_df['engineer_comments_reduct'] = combined_df['engineer_comments_reduct'].fillna('')\n",
        "\n",
        "# Подготовка признаков с помощью TF-IDF на основе столбцов 'Суть обращения' и 'Комментарии инженера'\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(combined_df['appeals_reduct'] + \" \" + combined_df['engineer_comments_reduct'])\n",
        "\n",
        "# Целевая переменная - классы из столбца 'Характер обращ'\n",
        "y = combined_df['Характер обращ'].fillna('')  # Замена NaN на пустые строки в целевой переменной\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Проверка и удаление строк с NaN в обучающих данных\n",
        "# В случае, если после разбиения всё ещё остались NaN\n",
        "X_train = X_train[~pd.isnull(y_train)]\n",
        "y_train = y_train[~pd.isnull(y_train)]\n",
        "\n",
        "# Инициализация модели логистической регрессии\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания на тестовых данных\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка точности модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Точность модели: {accuracy:.4f}\")\n",
        "\n",
        "# Полный отчёт по классификации (Precision, Recall, F1-score)\n",
        "print(\"\\nОтчёт по классификации:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Сохранение очищенного DataFrame в формате CSV (если нужно)\n",
        "output_csv_path = '/content/drive/MyDrive/Unilit/final_appeals_file.csv'\n",
        "combined_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(\"Данные успешно подготовлены и модель оценена.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me8qo9l1e4oz",
        "outputId": "53544c57-52cc-488d-e217-bc22f22a1153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели: 0.7812\n",
            "\n",
            "Отчёт по классификации:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Неисправность       0.78      1.00      0.88        25\n",
            "   Расписание       0.00      0.00      0.00         1\n",
            "        Связь       0.00      0.00      0.00         6\n",
            "\n",
            "     accuracy                           0.78        32\n",
            "    macro avg       0.26      0.33      0.29        32\n",
            " weighted avg       0.61      0.78      0.69        32\n",
            "\n",
            "Данные успешно подготовлены и модель оценена.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "судя по отчёту, модель показывает хорошие результаты для класса \"Неисправность\", но не справляется с другими классами (\"Расписание\" и \"Связь\")"
      ],
      "metadata": {
        "id": "41W3T2C_j96K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pymorphy2\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Инициализация анализатора pymorphy2\n",
        "ma = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "# Загрузка данных\n",
        "file_path = '/content/drive/MyDrive/Unilit/clean_appeals_file.csv'\n",
        "combined_df = pd.read_csv(file_path)\n",
        "\n",
        "# Замена NaN на пустые строки в столбцах 'appeals_reduct' и 'engineer_comments_reduct'\n",
        "combined_df['appeals_reduct'] = combined_df['appeals_reduct'].fillna('')\n",
        "combined_df['engineer_comments_reduct'] = combined_df['engineer_comments_reduct'].fillna('')\n",
        "\n",
        "# Подготовка признаков с помощью TF-IDF на основе столбцов 'Суть обращения' и 'Комментарии инженера'\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(combined_df['appeals_reduct'] + \" \" + combined_df['engineer_comments_reduct'])\n",
        "\n",
        "# Целевая переменная - классы из столбца 'Характер обращ'\n",
        "y = combined_df['Характер обращ'].fillna('')  # Замена NaN на пустые строки в целевой переменной\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Проверка и удаление строк с NaN в обучающих данных\n",
        "# В случае, если после разбиения всё ещё остались NaN\n",
        "X_train = X_train[~pd.isnull(y_train)]\n",
        "y_train = y_train[~pd.isnull(y_train)]\n",
        "\n",
        "# Инициализация модели логистической регрессии с учетом баланса классов\n",
        "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания на тестовых данных\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка точности модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Точность модели: {accuracy:.4f}\")\n",
        "\n",
        "# Полный отчёт по классификации (Precision, Recall, F1-score)\n",
        "print(\"\\nОтчёт по классификации:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836b7b6b-7f2d-4526-e0f1-ef0110df9554",
        "id": "Hu4rfRl6kFEa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели: 0.5938\n",
            "\n",
            "Отчёт по классификации:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "                    0.00      0.00      0.00         0\n",
            "Неисправность       0.94      0.64      0.76        25\n",
            "   Расписание       0.00      0.00      0.00         1\n",
            "        Связь       1.00      0.50      0.67         6\n",
            "\n",
            "     accuracy                           0.59        32\n",
            "    macro avg       0.49      0.29      0.36        32\n",
            " weighted avg       0.92      0.59      0.72        32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pymorphy2\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Инициализация анализатора pymorphy2\n",
        "ma = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "# Загрузка данных\n",
        "file_path = '/content/drive/MyDrive/Unilit/clean_appeals_file.csv'\n",
        "combined_df = pd.read_csv(file_path)\n",
        "\n",
        "# Удаление строк с пустыми значениями в классе 'Характер обращ'\n",
        "combined_df = combined_df[combined_df['Характер обращ'].notna() & (combined_df['Характер обращ'] != '')]\n",
        "\n",
        "# Замена NaN на пустые строки в столбцах 'appeals_reduct' и 'engineer_comments_reduct'\n",
        "combined_df['appeals_reduct'] = combined_df['appeals_reduct'].fillna('')\n",
        "combined_df['engineer_comments_reduct'] = combined_df['engineer_comments_reduct'].fillna('')\n",
        "\n",
        "# Подготовка признаков с помощью TF-IDF на основе столбцов 'Суть обращения' и 'Комментарии инженера'\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(combined_df['appeals_reduct'] + \" \" + combined_df['engineer_comments_reduct'])\n",
        "\n",
        "# Целевая переменная - классы из столбца 'Характер обращ'\n",
        "y = combined_df['Характер обращ'].fillna('')  # Замена NaN на пустые строки в целевой переменной\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Удаление строк с NaN в обучающих и тестовых данных\n",
        "X_train = X_train[~pd.isnull(y_train)]\n",
        "y_train = y_train[~pd.isnull(y_train)]\n",
        "\n",
        "X_test = X_test[~pd.isnull(y_test)]\n",
        "y_test = y_test[~pd.isnull(y_test)]\n",
        "\n",
        "# Инициализация модели Random Forest\n",
        "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания на тестовых данных\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка точности модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Точность модели: {accuracy:.4f}\")\n",
        "\n",
        "# Полный отчёт по классификации (Precision, Recall, F1-score)\n",
        "print(\"\\nОтчёт по классификации:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ip0aNbyk2dG",
        "outputId": "9347fc62-ca80-48bb-f663-4ba5fc1721b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели: 0.7812\n",
            "\n",
            "Отчёт по классификации:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Неисправность       0.80      0.96      0.87        25\n",
            "        Связь       0.50      0.14      0.22         7\n",
            "\n",
            "     accuracy                           0.78        32\n",
            "    macro avg       0.65      0.55      0.55        32\n",
            " weighted avg       0.73      0.78      0.73        32\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Загрузка данных**:\n",
        "   данные из CSV-файла, содержащие текстовые данные о \"Суть обращения\" и \"Комментарии инженера\", а также классы обращений в столбце \"Характер обращ\".\n",
        "\n",
        "2. **Предобработка данных**:\n",
        "   - **Очистка текста**: Все текстовые данные очищаются от пропущенных значений (NaN) в столбцах `'appeals_reduct'` и `'engineer_comments_reduct'`. Это важно для того, чтобы текст был чистым и готовым для векторизации.\n",
        "   - **Удаление пустых строк в столбце классов**: удаляем строки, где в столбце `'Характер обращ'` есть пустые значения, чтобы избежать проблем при обучении модели.\n",
        "\n",
        "3. **Применение TF-IDF**:\n",
        "   - **TF-IDF векторизация**: Ты применяем `TfidfVectorizer`, который преобразует текст в числовые признаки (векторы). Это необходимо, чтобы алгоритмы машинного обучения могли работать с текстом.\n",
        "   - **Что делает TF-IDF**:\n",
        "     - **TF (Term Frequency)**: рассчитывает частоту появления слова в документе.\n",
        "     - **IDF (Inverse Document Frequency)**: снижает вес слов, которые часто встречаются в наборе данных, и увеличивает вес редких слов.\n",
        "   - В результате каждое обращение и комментарий превращаются в набор чисел, которые описывают важность слов.\n",
        "\n",
        "4. **Разделение данных на обучающую и тестовую выборки**:\n",
        "   разделяем данные на обучающие (80%) и тестовые (20%) с помощью `train_test_split`.\n",
        "\n",
        "5. **Инициализация модели Random Forest**:\n",
        "   - **Random Forest** — это ансамблевый алгоритм, который использует несколько деревьев решений для классификации. Каждое дерево строится на случайной подвыборке признаков, что делает модель более устойчивой и менее склонной к переобучению.\n",
        "   - используем параметр `class_weight='balanced'`, чтобы модель учитывала дисбаланс классов (когда один класс сильно преобладает над другими). Это помогает сбалансировать вес для каждого класса.\n",
        "\n",
        "6. **Обучение модели**:\n",
        "   Модель Random Forest обучается на векторизованных текстах и классах обращений. Она строит несколько деревьев решений и использует их, чтобы предсказать класс на основе данных.\n",
        "\n",
        "7. **Предсказание на тестовых данных**:\n",
        "   После обучения модель предсказывает классы для тестовой выборки (20% данных, которые не использовались для обучения). Это помогает проверить, насколько хорошо модель может классифицировать новые, ранее невидимые данные.\n",
        "\n",
        "8. **Оценка модели**:\n",
        "   - **Точность модели** (`accuracy`) — это доля правильных предсказаний от общего числа примеров.\n",
        "   - **Отчёт по классификации** (`classification_report`) показывает более детальные метрики для каждого класса:\n",
        "     - **Precision** — точность: доля правильных предсказаний данного класса среди всех предсказанных как этот класс.\n",
        "     - **Recall** — полнота: доля правильно предсказанных примеров данного класса среди всех реальных примеров этого класса.\n",
        "     - **F1-score** — гармоническое среднее между Precision и Recall.\n",
        "     - **Support** — количество примеров в тестовой выборке для каждого класса.\n",
        "\n",
        "### Результаты:\n",
        "- Модель достигла точности **0.7812**, что означает, что 78.12% предсказаний были верными.\n",
        "- **Класс \"Неисправность\"**: имеет высокую точность и полноту, так как этот класс доминирует в данных (25 примеров из 32). Модель хорошо его предсказывает.\n",
        "- **Класс \"Связь\"**: здесь модель показывает низкие значения Recall (0.14), так как у неё мало данных для этого класса, что мешает ей правильно идентифицировать такие случаи.\n",
        "\n",
        "### Основные выводы:\n",
        "- Модель хорошо обучилась на большом классе \"Неисправность\", но плохо справляется с меньшим классом \"Связь\", что типично для несбалансированных данных.\n",
        "- Использование **class_weight='balanced'** помогло немного улучшить результаты для меньших классов."
      ],
      "metadata": {
        "id": "Ca9IvN-vmZme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cF5eHY_6nIh5"
      }
    }
  ]
}